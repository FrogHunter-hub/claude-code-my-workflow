# Table II — Summary Statistics for Panel Construction

**Date:** 2026-02-12
**Section:** II.D. Panel Construction
**Status:** COMPLETED

---

## Plan

### Context

Section II.D describes the firm–technology–quarter panel and ends with:
> "Table~II reports summary statistics for the resulting panel."

A `% TODO` comment on line 218 of `main.tex` confirmed this table hadn't been built yet. The task was to (1) write a Python script that constructs the panel from raw data and computes summary statistics, (2) generate a LaTeX table matching the existing style in `Overleaf/Tables/`, and (3) reconcile a macro category naming inconsistency between the Python and Stata scripts.

### Data Sources

1. **AllTech file** (443,478 rows) — `data/raw/AllTech_2002-2024_with_LLM_results(with Causal and non-Causal snippets).csv`
   - Used for Panel A (technology snippet statistics before causal filtering)
   - Key columns: `identified_technology`, `Year`, `File`, `Technology`, `detailed_causal_analysis`

2. **Causal snippets file** (581,449 rows) — `data/raw/Causal_Snippets_with_Categories.csv`
   - Used for Panels B–E (causal panel after dedup + threshold)
   - Key columns: `gvkey`, `technology`, `dateQ`, `side`, `input_id`, `macro_id`, `macro_name`, `sic`, `loc`

### Pipeline Design

**Panel A (technology snippets):**
1. Load AllTech with `usecols` to manage memory
2. Filter to valid technology: `identified_technology` not in {"none", NaN}
3. Compute: total snippets, tech-relevant snippets, causal ratio, unique transcripts/technologies, year range, snippets-per-transcript distribution

**Panels B–E (causal panel):**
1. Load causal snippets (key columns only)
2. Drop rows with missing `gvkey`, `technology`, `dateQ`, `side`, or `macro_id`
3. Validate `macro_id` in {1..5} and macro names against data
4. Deduplicate on `(gvkey, technology, dateQ, side, input_id, macro_id)`
5. Collapse to firm–tech–quarter–side–macro counts
6. Pivot to wide: `n1..n5`, compute `N_side`, shares `share_c = n_c / N_side`
7. Apply ≥3 threshold per side
8. Split cause/effect, inner-join on `(gvkey, technology, dateQ)` → joint panel
9. Compute `N_total`, `cause_effect_ratio`

**Table structure (5 panels):**

| Panel | Content | Statistics |
|-------|---------|------------|
| A. Technology Snippet Extraction | Total/tech-relevant snippets, causal ratio, unique dimensions, sample period | Scalars + Mean/SD/P25/Median/P75 for per-transcript |
| B. Causal Panel Dimensions | Obs count, unique firms, technologies, quarters, countries | Scalars + distribution for obs-per-firm |
| C. Cause Shares | 5 macro categories | Mean, SD, P25, Median, P75 |
| D. Effect Shares | 5 macro categories | Mean, SD, P25, Median, P75 |
| E. Intensity Measures | N_total, N_cause, N_effect, cause/effect ratio | Mean, SD, P25, Median, P75 |

### Files to Create/Modify

| File | Action |
|------|--------|
| `src/py/03_table_II_summary_stats.py` | **Create** — main script |
| `Overleaf/Tables/summary_stats.tex` | **Create** (generated by script) |
| `data_processed/panel_ikt.csv` | **Create** (generated by script) |
| `results/tables/table_II_summary_stats.csv` | **Create** (generated by script) |
| `results/runs/03_table_II_<timestamp>.json` | **Create** (run manifest) |
| `Overleaf/Tables/alltables.tex` | **Modify** — add `\input{Tables/summary_stats}` |
| `Overleaf/main.tex` | **Modify** — remove TODO on line 218 |

---

## Execution Summary

### Step 1: Created Python Script

Wrote `src/py/03_table_II_summary_stats.py` (~540 lines). Key design decisions:
- `usecols` on AllTech read to manage memory; `del` after Panel A to free before loading causal data
- `pd.to_numeric(..., errors="coerce")` for safe type casting
- Explicit `validate="1:1"` and `validate="m:1"` on merges
- Assertions that `macro_id` ∈ {1..5} and macro names match raw data column
- Shares-sum-to-one check is an assertion, not just a print
- Deterministic `firm_info` via `sort_values("dateQ")` before `drop_duplicates`
- `encoding="utf-8"` on all I/O (Windows default is cp1252)

### Step 2: Updated LaTeX Files

- Added `\input{Tables/summary_stats}` to `alltables.tex` (before `macroshare`)
- Removed TODO comment from `main.tex` line 218

### Step 3: Ran and Verified

Script output:
```
PANEL A:
  Total snippets in corpus: 443,478
  Technology-relevant snippets: 279,085 (62.9%)
  Causal ratio: 67.2%
  Unique transcripts: 82,169
  Unique technologies: 29
  Sample period: 2002–2024

PANELS B-E:
  Raw causal snippets: 581,449
  After dropping missing fields: 527,725 (dropped 53,724)
  After dedup: 402,804 (removed 124,921)
  After >=3 threshold: 43,181 side-obs (dropped 83,758)
  Cause side-obs: 15,587   Effect side-obs: 27,594
  Joint panel: 13,723 obs (cause-only dropped: 1,864; effect-only dropped: 13,871)
  Shares sum check PASSED (cause=1.000000, effect=1.000000)
  Panel: 13,723 obs, 2,812 firms, 29 techs, 92 quarters, 42 countries
```

### Step 4: Review-Fix Cycle

**Python reviewer** (score: 72/100 → fixes applied → re-run passed):
- Added `encoding="utf-8"` to all `read_csv()` / `to_csv()` / `write_text()` calls
- Replaced `astype(int)` with `pd.to_numeric(..., errors="coerce")` + NaN guard
- Added `validate=` parameter to both merges
- Added macro_id range assertion and macro_name validation against raw data
- Converted sanity checks from `print()` to `assert`
- Fixed CSV column name bug: `"Sd"` → `"SD"` (via explicit `STAT_COLS` mapping)
- Made `firm_info` extraction deterministic (sort by `dateQ` descending)

**Empirical reviewer** flagged:
- Inner join drops 1,864 cause-only and 13,871 effect-only observations — may warrant a footnote in Section II.D
- Threshold of ≥3 creates share discreteness at boundary (P25 of cause spans = 3.0)
- Compositional data properties of shares not discussed in paper
- **Critical**: macro category name inconsistency between Python and Stata scripts

### Step 5: Reconciled Macro Category Names

**Root cause:** The Stata script (`02_tableV_variance.do`) had hardcoded column labels that didn't match the `macro_id → macro_name` mapping in the raw CSV:

| Issue | Detail |
|-------|--------|
| Cause macro_id=3 | Stata had "Competitive Landscape Dynamics" (a fine-grained `category_name`); correct macro name is "Regulatory and Policy Drivers" |
| Effect macro_id 1–5 | All 5 labels were permuted (e.g., EFFECT1 said "Market Expansion & Adoption" but share1 = macro_id 1 = "Revenue & Financial Growth") |

The decomposition *numbers* in Table V were always correct — only the column **headers** were mislabeled.

**Files fixed:**

| File | Change |
|------|--------|
| `src/stata/02_tableV_variance.do` | Fixed CAUSE3, EFFECT1-5 locals + added provenance comment |
| `Overleaf/Tables/vardecomp.tex` | Fixed Panel A col 3 + Panel B cols 1-5 headers |
| `results/tables/vardecomp.tex` | Same fixes (Stata-generated copy) |
| `MEMORY.md` | Added `[LEARN:taxonomy]` entry documenting the correct mapping |

**Safeguard:** The Python script now validates macro names against the raw CSV on every run, preventing future drift.

---

## Final Outputs

| File | Description |
|------|-------------|
| `src/py/03_table_II_summary_stats.py` | Python script (panel construction + Table II generation) |
| `Overleaf/Tables/summary_stats.tex` | LaTeX Table II (5 panels) |
| `data_processed/panel_ikt.csv` | Full panel (13,723 obs, reusable downstream) |
| `results/tables/table_II_summary_stats.csv` | Machine-readable summary statistics |
| `results/runs/03_table_II_*.json` | Run manifest |

---

## Key Numbers (Table II)

| Panel | Highlights |
|-------|-----------|
| **A. Snippets** | 443,478 total → 279,085 tech-relevant (62.9%) → 67.2% causal ratio, 29 techs, 82,169 transcripts, 2002–2024 |
| **B. Panel** | 13,723 obs, 2,812 firms, 29 techs, 92 quarters, 42 countries |
| **C. Cause shares** | Top: Tech Innovation (0.311), Market Demand (0.297); Bottom: Regulatory (0.064) |
| **D. Effect shares** | Top: Market Expansion (0.304), Revenue Growth (0.243); Bottom: Op. Efficiency (0.104) |
| **E. Intensity** | Mean 16.0 total spans, cause/effect ratio 0.80 |

---

## Step 6: Updated Section II.D Manuscript Text

Enriched the prose in `Overleaf/main.tex` Section II.D with concrete panel dimensions from Table II, then ran the proofreader and applied fixes.

### New content added (lines 219–221)

1. **Panel dimensions paragraph** — "The estimation sample contains 13,723 firm–technology–quarter observations spanning 2,812 unique firms, all 29 technologies, and 92 calendar quarters (2002:Q1–2024:Q4) across 42 countries."
2. **Intensity description** — Median 12 spans (5 cause, 7 effect), mean cause-to-effect ratio 0.80.
3. **Share composition highlights** — Cause side dominated by Tech Innovation (0.311) and Market Demand (0.297); effect side led by Market Expansion (0.304) and Revenue Growth (0.243).
4. **Cross-table reconciliation note** — Explains why observation-level means (Table II) differ from pooled span-level shares (Table I): "These observation-level means differ slightly from the pooled span-level shares in Table I, which weight each span equally regardless of observation size."
5. **Obs-per-firm statistics** — "The typical firm contributes a modest number of observations—the median is two and the mean is 4.9."
6. **Robustness placeholder** — Added "(Online Appendix Table XX)" with TODO for future table number.

### Proofreading fixes applied

| Issue | Severity | Fix |
|-------|----------|-----|
| "total snippet count" → "total span count" | High | Fixed in `main.tex`, `summary_stats.tex` (Panel E label), and `03_table_II_summary_stats.py`. $N_{ikt}$ sums spans not snippets. |
| "12 causal spans—5 and 7" ambiguous | High | → "12 spans in total, with medians of 5 on the cause side and 7 on the effect side". Removes "causal"≠"cause" confusion; clarifies three separate medians. |
| Cross-table scale inconsistency | High | Added sentence explaining Table I (pooled %) vs Table II (observation-mean proportions) use different aggregation levels. |
| Rounded shares imprecise | Medium | Changed from 2-decimal (0.31, 0.30) to exact 3-decimal (0.311, 0.297, 0.064, 0.304, 0.243) matching the table. |
| Robustness claim unanchored | Medium | Added "(Online Appendix Table XX)" placeholder with TODO comment. |

### Files modified in this step

| File | Change |
|------|--------|
| `Overleaf/main.tex` | Rewrote Section II.D paragraphs 3–4 with panel dimensions, share highlights, cross-table note, obs-per-firm stats, robustness placeholder; fixed "snippet"→"span" |
| `Overleaf/Tables/summary_stats.tex` | Panel E row label: "Total snippet count" → "Total span count" |
| `src/py/03_table_II_summary_stats.py` | Matching label fix for future regenerations |

---

## Open Items for Future Sessions

1. **Inner join attrition footnote** — Consider adding to Section II.D: "The inner join requires both sides to meet the threshold, dropping X cause-only and Y effect-only observations."
2. **Threshold robustness** — Test sensitivity to ≥2 and ≥5 thresholds.
3. **Sample funnel** — Bridge abstract numbers (450,095 transcripts, 19,469 firms, 94 countries) to pipeline output in Table II notes.
4. **Compositional data** — Discuss share discreteness near threshold and omitted-category collinearity in Section V regressions.
5. **Online Appendix Table XX** — Create the firm–quarter collapsed robustness table and replace the placeholder reference.
